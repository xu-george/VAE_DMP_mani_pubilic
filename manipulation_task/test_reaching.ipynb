{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test via point, and end point for the reaching task in the pybullet working space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/binzhao/binzhao_u/VAE_DMP_mani/manipulation_task\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os, time, tqdm, sys\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# add parent dictionary to path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from models.vae import TrajGen, DM\n",
    "from models.dmp import CanonicalSystem, SingleDMP\n",
    "from utils.data_loader import TorqueLoader as Torque_dataset\n",
    "from utils.early_stop import EarlyStop\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "print(os.getcwd())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create cVAE-dmp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# create dmp model \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "run_time = 1\n",
    "dt = 0.01\n",
    "# define the shape of each damonstration\n",
    "shape = (5, 100)\n",
    "# create dataset for training and testing\n",
    "cs = CanonicalSystem(dt=0.01, ax=1)\n",
    "dmp = SingleDMP(n_bfs=50, cs=cs, run_time=1.0, dt=0.01)\n",
    "print(\"device: \", device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.639522 40.198143 65.1502   54.927094 89.87197 ] [-35.03298   -13.038735   -6.0426774  -4.746726  -25.30069  ]\n"
     ]
    }
   ],
   "source": [
    "# get max, min from dataset to de-normalize the data\n",
    "train_dataset = Torque_dataset(run_time=1, dmp=dmp, dt=0.01, dof=2)\n",
    "train_dataset.load_data('../data/manipulation_data/train_torque.npz', device=device)\n",
    "train_dataset.torque = train_dataset.normalize_data(device=device)\n",
    "\n",
    "#get normalize  paramters of data\n",
    "max = train_dataset.max.cpu().numpy()\n",
    "min = train_dataset.min.cpu().numpy()\n",
    "print(max, min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "save_name = \"./models/cVAE_torque_manipulation.pt\"\n",
    "checkpoint = torch.load(save_name, map_location=device)\n",
    "dict = checkpoint['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the decoder part only -- generator, label_embedding\n",
    "decoder_param = OrderedDict() \n",
    "    \n",
    "key_word_1 = {\"decoder.\"}\n",
    "key_word_2 = {\"label_embedding.\"}\n",
    "\n",
    "for layer_name, param in checkpoint[\"net\"].items():\n",
    "    for key_word in key_word_1:\n",
    "        if key_word in layer_name:            \n",
    "            layer_name = layer_name.replace(key_word, \"\")            \n",
    "            decoder_param[layer_name] = param\n",
    "\n",
    "torch.save(decoder_param, \"./models/decoder.pt\")\n",
    "\n",
    "# save label encoder\n",
    "label_encoder_param = OrderedDict()\n",
    "for layer_name, param in checkpoint[\"net\"].items():\n",
    "    for key_word in key_word_2:\n",
    "        if key_word in layer_name:            \n",
    "            layer_name = layer_name.replace(key_word, \"\")            \n",
    "            label_encoder_param[layer_name] = param\n",
    "\n",
    "torch.save(label_encoder_param, \"./models/label_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trajectory generator -- decoder + dynamics system\n",
    "shape = (5, 100)\n",
    "nclass = 4\n",
    "nhid = 8\n",
    "ncond = 8\n",
    "\n",
    "# create trajectory generator\n",
    "traj_gen = TrajGen(shape=shape, nclass=nclass, nhid=nhid, ncond=ncond, min=min, max=max, device=device)\n",
    "# send to device\n",
    "traj_gen.decoder_o.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "traj_gen.decoder_n.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "traj_gen.label_embedding.load_state_dict(torch.load('./models/label_encoder.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pybullet based environment and load demonstration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demonstrations:  3\n",
      "task_id_1 (19, 5)\n",
      "task_id_2 (33, 5)\n",
      "task_id_3 (27, 5)\n"
     ]
    }
   ],
   "source": [
    "robot_model_path = \"../manipulation_env/models/urdf/ur10_robotiq_85.urdf\"\n",
    "table_path = \"../manipulation_env/models/urdf/objects/table/table.urdf\"\n",
    "block_path = \"../manipulation_env/models/YcbPottedMeatCan/model.urdf\"\n",
    "\n",
    "demon_path = \"../data/manipulation_data\"\n",
    "\n",
    "# create dictionary to store the data\n",
    "demons_data = {}\n",
    "for file in os.listdir(demon_path):\n",
    "\n",
    "    if file.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(demon_path, file), allow_pickle=True)\n",
    "        task_id = int(file.split(\"_\")[0])\n",
    "        demons_data[\"task_id_\" + str(task_id)] = data\n",
    "print(\"Number of demonstrations: \", len(demons_data))  \n",
    "\n",
    "# show the structure of the data\n",
    "for key, value in demons_data.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jun 24 2024 11:27:31\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "[jointInfo(id=0, name='world_arm_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=1, name='robot_shoulder_pan_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=330.0, maxVelocity=2.16, controllable=True), jointInfo(id=2, name='robot_shoulder_lift_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=330.0, maxVelocity=2.16, controllable=True), jointInfo(id=3, name='robot_elbow_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-3.14159265359, upperLimit=3.14159265359, maxForce=150.0, maxVelocity=3.15, controllable=True), jointInfo(id=4, name='robot_wrist_1_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=5, name='robot_wrist_2_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=6, name='robot_wrist_3_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=7, name='robot_ee_fixed_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=8, name='robotiq_85_base_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=9, name='finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=10, name='left_outer_finger_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=11, name='left_inner_finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-0.8757, upperLimit=0.0, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=12, name='left_inner_finger_pad_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=13, name='left_inner_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8757, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=14, name='right_outer_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.81, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=15, name='right_outer_finger_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=16, name='right_inner_finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-0.8757, upperLimit=0.0, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=17, name='right_inner_finger_pad_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=18, name='right_inner_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8757, maxForce=1000.0, maxVelocity=2.0, controllable=True)]started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA Tegra Orin (nvgpu)/integrated\n",
      "GL_VERSION=3.3.0 NVIDIA 35.5.0\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3.0 NVIDIA 35.5.0\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA Tegra Orin (nvgpu)/integrated\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: robot_ee_link\n",
      "\n",
      "processing baseLink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing baseLink\n"
     ]
    }
   ],
   "source": [
    "# create pybullet environment\n",
    "from manipulation_env.env import ManiEnv\n",
    "from manipulation_env.robot import UR10Robotiq85\n",
    "robot = UR10Robotiq85(model_path=robot_model_path)\n",
    "env = ManiEnv(robot, block_path=block_path, table_path=table_path, vis=True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: reaching task, test basic cVAE-dmp model, and end point fine-tuning\n",
    "the robot manipulation space:\n",
    "- x: [0.3, 0.8]\n",
    "- y: [-0.45, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the initial position of end-effector, and block in the demonstration\n",
    "gripper_offset = 0.17\n",
    "block_position = np.array([0, 0, 0.04])\n",
    "reach_demo = demons_data[\"task_id_1\"]\n",
    "robot_inial_pose = reach_demo[0]\n",
    "robot_end_pose = reach_demo[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [00:19, 17.94it/s]/media/binzhao/binzhao_u/VAE_DMP_mani/models/vae.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x0).to(self.device)\n",
      "/media/binzhao/binzhao_u/VAE_DMP_mani/models/vae.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  goal = torch.tensor(goal).to(self.device)\n"
     ]
    }
   ],
   "source": [
    "# --------------------- random block position --------------------------\n",
    "# reset the environment\n",
    "# store all the reaching trajectory\n",
    "import time \n",
    "tractories = []\n",
    "\n",
    "env.clean_traj_plot()\n",
    "env.step(robot_inial_pose)\n",
    "\n",
    "for num_traj in range(30):   \n",
    "    block_position = np.array([0, 0, 0.04])\n",
    "    random_x = np.random.rand() * 0.3 + 0.5\n",
    "    random_y = (np.random.rand() - 0.5) * 0.8\n",
    "    block_position[0] = random_x\n",
    "    block_position[1] = random_y\n",
    "\n",
    "    # set the final position of the robot\n",
    "    env.reset_block(pos = block_position, euler_angle=[0, 0, 0])\n",
    "\n",
    "    block_pos_sim = env.get_block_position()\n",
    "    reach_point = block_pos_sim + np.array([0, 0, 0.02 + gripper_offset])\n",
    "    robot_end_pose[:3] = reach_point\n",
    "\n",
    "    # generate trajectory from cVAE-dmp    \n",
    "    traj_gen.eval()\n",
    "    torch_robot_inial_pose = torch.tensor(robot_inial_pose, dtype=torch.float32).to(device)\n",
    "    torch_robot_end_pose = torch.tensor(robot_end_pose, dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        traj = traj_gen(class_idx=1, x0=torch_robot_inial_pose, goal=torch_robot_end_pose)     \n",
    " \n",
    "    traj = traj.cpu().numpy()[0]\n",
    "\n",
    "    # # plot the trajectory\n",
    "    env.traj_plot(traj[:3,:].T)\n",
    "\n",
    "    # check if touch the block\n",
    "    success = False\n",
    "    env.step(robot_inial_pose)\n",
    "    for i in range(traj.shape[1]):\n",
    "        env.step(traj[:, i])\n",
    "        if env.check_touching():\n",
    "            success = True\n",
    "            break\n",
    "    \n",
    "    # store the trajectory\n",
    "    tractories.append({\"traj\":traj, \"success\":success, \"block_pose\":block_pos_sim})  \n",
    "    print(\"Trajectory: \", num_traj, \"Success: \", success)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savez(\"reaching_trajecotries.npz\", tractories=tractories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "reaching_results = np.load(\"./save_trajectory/reaching_trajecotries.npz\", allow_pickle=True)\n",
    "# calculate the success rate\n",
    "success_rate = 0\n",
    "for traj in reaching_results[\"tractories\"]:\n",
    "    if traj[\"success\"]:\n",
    "        success_rate += 1\n",
    "\n",
    "print(\"Success rate: \", success_rate/len(reaching_results[\"tractories\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
