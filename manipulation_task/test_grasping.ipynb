{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test via point, and end point of grasping task in the pybullet working space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/binzhao/Documents/code/VAE_DMP_mani/manipulation_task\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os, time, tqdm, sys\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# add parent dictionary to path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from models.vae import TrajGen, DM\n",
    "from models.dmp import CanonicalSystem, SingleDMP\n",
    "from utils.data_loader import TorqueLoader as Torque_dataset\n",
    "from utils.early_stop import EarlyStop\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "print(os.getcwd())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create cVAE-dmp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# create dmp model \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "run_time = 1\n",
    "dt = 0.01\n",
    "# define the shape of each damonstration\n",
    "shape = (5, 100)\n",
    "# create dataset for training and testing\n",
    "cs = CanonicalSystem(dt=0.01, ax=1)\n",
    "dmp = SingleDMP(n_bfs=50, cs=cs, run_time=1.0, dt=0.01)\n",
    "print(\"device: \", device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.639522 40.198143 65.1502   54.927094 89.87197 ] [-35.03298   -13.038735   -6.0426774  -4.746726  -25.30069  ]\n"
     ]
    }
   ],
   "source": [
    "# get max, min from dataset to de-normalize the data\n",
    "train_dataset = Torque_dataset(run_time=1, dmp=dmp, dt=0.01, dof=2)\n",
    "train_dataset.load_data('../data/manipulation_data/train_torque.npz', device=device)\n",
    "train_dataset.torque = train_dataset.normalize_data(device=device)\n",
    "\n",
    "#get normalize  paramters of data\n",
    "max = train_dataset.max.cpu().numpy()\n",
    "min = train_dataset.min.cpu().numpy()\n",
    "print(max, min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39084/3714809421.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_name, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "save_name = \"./models/cVAE_torque_manipulation.pt\"\n",
    "checkpoint = torch.load(save_name, map_location=device)\n",
    "dict = checkpoint['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the decoder part only -- generator\n",
    "decoder_param = OrderedDict() \n",
    "    \n",
    "key_word_1 = {\"decoder.\"}\n",
    "key_word_2 = {\"label_embedding.\"}\n",
    "\n",
    "for layer_name, param in checkpoint[\"net\"].items():\n",
    "    for key_word in key_word_1:\n",
    "        if key_word in layer_name:            \n",
    "            layer_name = layer_name.replace(key_word, \"\")            \n",
    "            decoder_param[layer_name] = param\n",
    "\n",
    "torch.save(decoder_param, \"./models/decoder.pt\")\n",
    "\n",
    "# save label encoder\n",
    "label_encoder_param = OrderedDict()\n",
    "for layer_name, param in checkpoint[\"net\"].items():\n",
    "    for key_word in key_word_2:\n",
    "        if key_word in layer_name:            \n",
    "            layer_name = layer_name.replace(key_word, \"\")            \n",
    "            label_encoder_param[layer_name] = param\n",
    "\n",
    "torch.save(label_encoder_param, \"./models/label_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39084/1204908132.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  traj_gen.decoder_o.load_state_dict(torch.load('./models/decoder.pt'))\n",
      "/tmp/ipykernel_39084/1204908132.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  traj_gen.decoder_n.load_state_dict(torch.load('./models/decoder.pt'))\n",
      "/tmp/ipykernel_39084/1204908132.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  traj_gen.label_embedding.load_state_dict(torch.load('./models/label_encoder.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trajectory generator -- decoder + dynamics system\n",
    "shape = (5, 100)\n",
    "nclass = 4\n",
    "nhid = 8\n",
    "ncond = 8\n",
    "\n",
    "# create trajectory generator\n",
    "traj_gen = TrajGen(shape=shape, nclass=nclass, nhid=nhid, ncond=ncond, min=min, max=max, device=device)\n",
    "# send to device\n",
    "traj_gen.decoder_o.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "traj_gen.decoder_n.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "traj_gen.label_embedding.load_state_dict(torch.load('./models/label_encoder.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pybullet based environment and load demonstration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demonstrations:  3\n",
      "task_id_2 (33, 5)\n",
      "task_id_3 (35, 5)\n",
      "task_id_1 (19, 5)\n"
     ]
    }
   ],
   "source": [
    "robot_model_path = \"../manipulation_env/models/urdf/ur10_robotiq_85.urdf\"\n",
    "table_path = \"../manipulation_env/models/urdf/objects/table/table.urdf\"\n",
    "block_path = \"../manipulation_env/models/YcbPottedMeatCan/model.urdf\"\n",
    "\n",
    "demon_path = \"../data/manipulation_data\"\n",
    "\n",
    "# create dictionary to store the data\n",
    "demons_data = {}\n",
    "for file in os.listdir(demon_path):\n",
    "\n",
    "    if file.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(demon_path, file), allow_pickle=True)\n",
    "        task_id = int(file.split(\"_\")[0])\n",
    "        demons_data[\"task_id_\" + str(task_id)] = data\n",
    "print(\"Number of demonstrations: \", len(demons_data))  \n",
    "\n",
    "# show the structure of the data\n",
    "for key, value in demons_data.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:51:11\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) Graphics (RPL-P)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) Graphics (RPL-P)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "[jointInfo(id=0, name='world_arm_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=1, name='robot_shoulder_pan_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=330.0, maxVelocity=2.16, controllable=True), jointInfo(id=2, name='robot_shoulder_lift_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=330.0, maxVelocity=2.16, controllable=True), jointInfo(id=3, name='robot_elbow_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-3.14159265359, upperLimit=3.14159265359, maxForce=150.0, maxVelocity=3.15, controllable=True), jointInfo(id=4, name='robot_wrist_1_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=5, name='robot_wrist_2_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=6, name='robot_wrist_3_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-6.28318530718, upperLimit=6.28318530718, maxForce=54.0, maxVelocity=3.2, controllable=True), jointInfo(id=7, name='robot_ee_fixed_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=8, name='robotiq_85_base_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=9, name='finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=10, name='left_outer_finger_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=11, name='left_inner_finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-0.8757, upperLimit=0.0, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=12, name='left_inner_finger_pad_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=13, name='left_inner_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8757, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=14, name='right_outer_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.81, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=15, name='right_outer_finger_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=16, name='right_inner_finger_joint', type=0, damping=0.0, friction=0.0, lowerLimit=-0.8757, upperLimit=0.0, maxForce=1000.0, maxVelocity=2.0, controllable=True), jointInfo(id=17, name='right_inner_finger_pad_joint', type=4, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=-1.0, maxForce=0.0, maxVelocity=0.0, controllable=False), jointInfo(id=18, name='right_inner_knuckle_joint', type=0, damping=0.0, friction=0.0, lowerLimit=0.0, upperLimit=0.8757, maxForce=1000.0, maxVelocity=2.0, controllable=True)]\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: robot_ee_link\n",
      "processing baseLink\n",
      "processing baseLink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "# create pybullet environment\n",
    "from manipulation_env.env import ManiEnv\n",
    "from manipulation_env.robot import UR10Robotiq85\n",
    "robot = UR10Robotiq85(model_path=robot_model_path)\n",
    "env = ManiEnv(robot, block_path=block_path, table_path=table_path, vis=True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: grasping task, test basic cVAE-dmp model, and end point fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grasping trajectory\n",
    "env.clean_traj_plot()\n",
    "gripper_offset = 0.17\n",
    "grasping_demo = demons_data[\"task_id_3\"]\n",
    "block_position = np.array([0, 0, 0.04])\n",
    "\n",
    "# relay the trajectory\n",
    "position = grasping_demo[20]\n",
    "block_position[0] = position[0]\n",
    "block_position[1] = position[1]\n",
    "env.reset_block(pos = block_position, euler_angle=[0, 0, 0])\n",
    "\n",
    "# # draw the inital trajectory \n",
    "env.traj_plot(grasping_demo[:, :3], color=[0.96, 0, 0.63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay the grasping demo\n",
    "env.reset_block(pos = block_position, euler_angle=[0, 0, 0])\n",
    "# for i in range(grasping_demo.shape[0]):\n",
    "#     env.step(grasping_demo[i])\n",
    "#     time.sleep(0.01)\n",
    "\n",
    "# # reset \n",
    "# env.step(grasping_demo[0])\n",
    "# env.reset_block(pos = block_position, euler_angle=[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3486it [02:29,  6.95it/s] /home/binzhao/Documents/code/VAE_DMP_mani/models/vae.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x0).to(self.device)\n",
      "/home/binzhao/Documents/code/VAE_DMP_mani/models/vae.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  goal = torch.tensor(goal).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14158it [03:18, 224.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  0 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24830it [04:07, 226.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  1 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36955it [05:03, 224.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  2 Success:  False\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47650it [05:52, 225.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  3 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58437it [06:42, 224.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  4 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69247it [07:31, 224.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  5 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79919it [08:20, 223.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  6 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90729it [09:10, 224.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  7 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101516it [09:58, 225.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  8 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112188it [10:47, 223.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  9 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122883it [11:35, 226.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  10 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "133555it [12:24, 224.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  11 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144250it [13:12, 224.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  12 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155037it [14:01, 225.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  13 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165709it [14:50, 226.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  14 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176519it [15:39, 223.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  15 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187329it [16:28, 225.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  16 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198116it [17:17, 224.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  17 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208788it [18:06, 224.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  18 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219598it [18:55, 224.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  19 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230408it [19:44, 224.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  20 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242529it [20:38, 225.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  21 Success:  False\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253316it [21:27, 225.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  22 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "263988it [22:16, 224.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  23 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "274683it [23:04, 224.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  24 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285470it [23:53, 224.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  25 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296280it [24:42, 226.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  26 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "306952it [25:30, 225.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  27 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "317631it [26:18, 226.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  28 Success:  True\n",
      "(5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "329650it [27:12, 226.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory:  29 Success:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "329650it [27:30, 226.56it/s]"
     ]
    }
   ],
   "source": [
    "# random put the block position and orientation\n",
    "robot_initial_pose = grasping_demo[0]\n",
    "robot_end_pose = grasping_demo[-1]\n",
    "\n",
    "block_position = np.array([0, 0, 0.04])\n",
    "env.clean_traj_plot()\n",
    "env.step(robot_initial_pose)\n",
    "\n",
    "tractories = []\n",
    "# random put the block and collect the trajectory\n",
    "for num_traj in range(30): \n",
    "\n",
    "    random_x = np.random.rand() * 0.3 + 0.5\n",
    "    random_y = (np.random.rand() - 0.5) * 0.8\n",
    "    block_position[0] = random_x\n",
    "    block_position[1] = random_y\n",
    "    block_orien = np.random.rand() * np.pi/2\n",
    "\n",
    "    # set the final position of the robot\n",
    "    env.reset_block(pos = block_position, euler_angle=[0, 0, block_orien])\n",
    "    \n",
    "    # get the grasping state\n",
    "    block_pos_sim = env.get_block_position()\n",
    "    grasp_point = block_pos_sim + np.array([0, 0, gripper_offset])\n",
    "    robot_end_pose[:3] = grasp_point\n",
    "    robot_end_pose[3] = block_orien\n",
    "    robot_end_pose[4] = 0.55\n",
    "\n",
    "    # get the trajectory\n",
    "    torch_robot_inial_pose = torch.tensor(robot_initial_pose, dtype=torch.float32).to(device)\n",
    "    torch_robot_end_pose = torch.tensor(robot_end_pose, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        traj = traj_gen(class_idx=3, x0=torch_robot_inial_pose, goal=torch_robot_end_pose)\n",
    "    \n",
    "    # convert to numpy\n",
    "    traj = traj.cpu().numpy()[0]\n",
    "    print(traj.shape)\n",
    "\n",
    "    # plot the trajectory\n",
    "    env.traj_plot(traj[:3,:].T)\n",
    "\n",
    "    # check if touch the block\n",
    "    success = False\n",
    "    env.step(robot_initial_pose)\n",
    "    for i in range(traj.shape[1]):\n",
    "        env.step(traj[:, i])\n",
    "        if env.check_grasping():\n",
    "            success = True\n",
    "            break\n",
    "    \n",
    "    # store the trajectory\n",
    "    tractories.append({\"traj\":traj, \"success\":success, \"block_pose\":block_pos_sim, block_orien:block_orien})  \n",
    "    print(\"Trajectory: \", num_traj, \"Success: \", success)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an initial trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate:  0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x74f021539340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the data\n",
    "np.savez(\"grasping_trajecotries.npz\", tractories=tractories)\n",
    "\n",
    "# print the success in the pushing\n",
    "success = 0\n",
    "for traj in tractories:\n",
    "    if traj[\"success\"]:\n",
    "        success += 1\n",
    "print(\"Success rate: \", success/len(tractories))\n",
    "\n",
    "# matplt plot the block position\n",
    "block_pos = []\n",
    "for traj in tractories:\n",
    "    block_pos.append(traj[\"block_pose\"])\n",
    "block_pos = np.array(block_pos)\n",
    "plt.scatter(block_pos[:,0], block_pos[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
